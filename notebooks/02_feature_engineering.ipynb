{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a52d089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training log loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATA_PATH = '../data/'\n",
    "OUTPUT_PATH = '../'\n",
    "\n",
    "train_log_df = pd.read_csv(os.path.join(DATA_PATH, 'train_log.csv'))\n",
    "print(\"Training log loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41933329",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_cache = {}\n",
    "def load_lightcurve(object_id: str, split: str) -> pd.DataFrame:\n",
    "    \"\"\"Loads lightcurve data for a single object, using a cache\"\"\"\n",
    "    file_path = os.path.join(DATA_PATH, split, \"train_full_lightcurves.csv\")\n",
    "    if file_path not in dataframe_cache:\n",
    "        try:\n",
    "            full_df = pd.read_csv(file_path)\n",
    "            dataframe_cache[file_path] = full_df\n",
    "        except FileNotFoundError:\n",
    "            return pd.DataFrame()\n",
    "    else:\n",
    "        full_df = dataframe_cache[file_path]\n",
    "    \n",
    "    object_df = full_df[full_df['object_id'] == object_id].copy()\n",
    "    return object_df\n",
    "\n",
    "def engineer_features(df: pd.DataFrame, object_id: str) -> dict:\n",
    "    \"\"\"Engineers a set of features for a single object's lightcurve data.\"\"\"\n",
    "    if df.empty:\n",
    "        return {}\n",
    "    \n",
    "    # Make a copy to avoid SettingWithCopyWarning\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Create flux ratio feature\n",
    "    df['Flux_Ratio'] = df['Flux'] / df['Flux_err']\n",
    "\n",
    "    agg_features = {\n",
    "        'Flux_mean': df['Flux'].mean(),\n",
    "        'Flux_std': df['Flux'].std(),\n",
    "        'Flux_min': df['Flux'].min(),\n",
    "        'Flux_max': df['Flux'].max(),\n",
    "        'Flux_median': df['Flux'].median(),\n",
    "        'Flux_skew': df['Flux'].skew(),\n",
    "        'Flux_err_mean': df['Flux_err'].mean(),\n",
    "        'Flux_err_std': df['Flux_err'].std(),\n",
    "        'Flux_Ratio_mean': df['Flux_Ratio'].mean(),\n",
    "        'Flux_Ratio_skew': df['Flux_Ratio'].skew(),\n",
    "    }\n",
    "\n",
    "    # Per Filter Agg\n",
    "    # Pivot to get columns for each filter\n",
    "    df_pivot = df.pivot_table(\n",
    "        index='Time (MJD)', columns='Filter', values='Flux'\n",
    "    )\n",
    "\n",
    "    # Cal. stats for each filter's flux\n",
    "    for f in ['u', 'g', 'r', 'i', 'z', 'y']:\n",
    "        if f in df_pivot.columns:\n",
    "            agg_features[f'{f}_Flux_mean'] = df_pivot[f].mean()\n",
    "            agg_features[f'{f}_Flux_std'] = df_pivot[f].std()\n",
    "            agg_features[f'{f}_Flux_max'] = df_pivot[f].max()\n",
    "            agg_features[f'{f}_Flux_min'] = df_pivot[f].min()\n",
    "        else:\n",
    "            # Fill with NaN if the filter is missing\n",
    "            agg_features[f'{f}_Flux_mean'] = np.nan\n",
    "            agg_features[f'{f}_Flux_std'] = np.nan\n",
    "            agg_features[f'{f}_Flux_max'] = np.nan\n",
    "            agg_features[f'{f}_Flux_min'] = np.nan\n",
    "    \n",
    "    agg_features['object_id'] = object_id\n",
    "\n",
    "    return agg_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "116444c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting feature engineering process for all training objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3043/3043 [00:11<00:00, 272.69it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting feature engineering process for all training objects...\")\n",
    "\n",
    "all_features = [\n",
    "    engineer_features(\n",
    "        load_lightcurve(row['object_id'], row['split']),\n",
    "        row['object_id']\n",
    "    )\n",
    "    for _, row in tqdm(train_log_df.iterrows(), total=len(train_log_df))\n",
    "]\n",
    "\n",
    "all_features = [f for f in all_features if f]\n",
    "train_features_df = pd.DataFrame(all_features)\n",
    "\n",
    "final_train_df = pd.merge(\n",
    "    train_log_df.drop(columns=['Z_err', 'SpecType']),\n",
    "    train_features_df,\n",
    "    on='object_id',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da03c240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Engineering Complete\n",
      "New feature dataframe shape: (3043, 40)\n",
      "Saved features to: ../train_features.csv\n",
      "\n",
      "--- New Training DataFrame Head ---\n",
      "                  object_id       Z    EBV  \\\n",
      "0  Dornhoth_fervain_onodrim  3.0490  0.110   \n",
      "1       Dornhoth_galadh_ylf  0.4324  0.058   \n",
      "2      Elrim_melethril_thul  0.4673  0.577   \n",
      "3        Ithil_tobas_rodwen  0.6946  0.012   \n",
      "4       Mirion_adar_Druadan  0.4161  0.058   \n",
      "\n",
      "                               English Translation     split  target  \\\n",
      "0  Trawn Folk (Dwarfs) + northern + Ents (people)   split_01       0   \n",
      "1    Trawn Folk (Dwarfs) + tree + drinking vessel   split_01       0   \n",
      "2                  Elves +  lover (fem.)  + breath  split_01       0   \n",
      "3                    moon +  roof  +  noble maiden  split_01       0   \n",
      "4            jewel, Silmaril  + father + Wild Man   split_01       0   \n",
      "\n",
      "   Flux_mean  Flux_std  Flux_min   Flux_max  ...  i_Flux_max  i_Flux_min  \\\n",
      "0   0.928483  4.803445 -2.756285  25.047343  ...   22.951323   -2.208366   \n",
      "1   0.388622  1.371481 -1.747082  11.375499  ...    5.193139   -0.373861   \n",
      "2   1.691347  2.640938 -6.400816   6.617915  ...    4.938633   -2.986740   \n",
      "3   0.375366  0.859759 -7.641818   5.353821  ...    2.218724   -0.758823   \n",
      "4   0.233832  1.146554 -3.060399   5.384463  ...    5.384463   -1.281058   \n",
      "\n",
      "   z_Flux_mean  z_Flux_std  z_Flux_max  z_Flux_min  y_Flux_mean  y_Flux_std  \\\n",
      "0     1.269393    7.572198   25.047343   -2.571101    -0.401845    2.583268   \n",
      "1     0.526814    1.490399    7.229639   -1.086687     0.706072    2.500888   \n",
      "2     4.010965    1.950649    6.617915    1.204449     0.032667    9.098320   \n",
      "3     0.531152    0.707160    2.986381   -1.248527     0.343268    1.806049   \n",
      "4     0.296310    1.099048    2.701716   -2.367630     0.288067    1.704348   \n",
      "\n",
      "   y_Flux_max  y_Flux_min  \n",
      "0    5.866250   -2.756285  \n",
      "1   11.375499   -1.747082  \n",
      "2    6.466151   -6.400816  \n",
      "3    5.353821   -7.641818  \n",
      "4    2.370519   -3.060399  \n",
      "\n",
      "[5 rows x 40 columns]\n",
      "\n",
      " --- New Training DataFrame Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3043 entries, 0 to 3042\n",
      "Data columns (total 40 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   object_id            3043 non-null   object \n",
      " 1   Z                    3043 non-null   float64\n",
      " 2   EBV                  3043 non-null   float64\n",
      " 3   English Translation  3043 non-null   object \n",
      " 4   split                3043 non-null   object \n",
      " 5   target               3043 non-null   int64  \n",
      " 6   Flux_mean            3043 non-null   float64\n",
      " 7   Flux_std             3043 non-null   float64\n",
      " 8   Flux_min             3043 non-null   float64\n",
      " 9   Flux_max             3043 non-null   float64\n",
      " 10  Flux_median          3043 non-null   float64\n",
      " 11  Flux_skew            3043 non-null   float64\n",
      " 12  Flux_err_mean        3043 non-null   float64\n",
      " 13  Flux_err_std         3043 non-null   float64\n",
      " 14  Flux_Ratio_mean      3043 non-null   float64\n",
      " 15  Flux_Ratio_skew      3043 non-null   float64\n",
      " 16  u_Flux_mean          3026 non-null   float64\n",
      " 17  u_Flux_std           3015 non-null   float64\n",
      " 18  u_Flux_max           3026 non-null   float64\n",
      " 19  u_Flux_min           3026 non-null   float64\n",
      " 20  g_Flux_mean          3042 non-null   float64\n",
      " 21  g_Flux_std           3041 non-null   float64\n",
      " 22  g_Flux_max           3042 non-null   float64\n",
      " 23  g_Flux_min           3042 non-null   float64\n",
      " 24  r_Flux_mean          3043 non-null   float64\n",
      " 25  r_Flux_std           3043 non-null   float64\n",
      " 26  r_Flux_max           3043 non-null   float64\n",
      " 27  r_Flux_min           3043 non-null   float64\n",
      " 28  i_Flux_mean          3043 non-null   float64\n",
      " 29  i_Flux_std           3043 non-null   float64\n",
      " 30  i_Flux_max           3043 non-null   float64\n",
      " 31  i_Flux_min           3043 non-null   float64\n",
      " 32  z_Flux_mean          3043 non-null   float64\n",
      " 33  z_Flux_std           3043 non-null   float64\n",
      " 34  z_Flux_max           3043 non-null   float64\n",
      " 35  z_Flux_min           3043 non-null   float64\n",
      " 36  y_Flux_mean          3027 non-null   float64\n",
      " 37  y_Flux_std           3024 non-null   float64\n",
      " 38  y_Flux_max           3027 non-null   float64\n",
      " 39  y_Flux_min           3027 non-null   float64\n",
      "dtypes: float64(36), int64(1), object(3)\n",
      "memory usage: 951.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Save it\n",
    "output_file_path = os.path.join(OUTPUT_PATH, 'train_features.csv')\n",
    "final_train_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Feature Engineering Complete\")\n",
    "print(f\"New feature dataframe shape: {final_train_df.shape}\")\n",
    "print(f\"Saved features to: {output_file_path}\")\n",
    "\n",
    "print(\"\\n--- New Training DataFrame Head ---\")\n",
    "print(final_train_df.head())\n",
    "\n",
    "print(\"\\n --- New Training DataFrame Info ---\")\n",
    "final_train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93fbb3e",
   "metadata": {},
   "source": [
    "Now I have transformed the complex, variable length time series data into a clean, fixed size tabular format(`(3043, 40)`). Each row now represents one astronomical object, and the columns are our engineered features. This format is ideal for ML models\n",
    "\n",
    "Now I can start implementing the basemodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1cc664",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
