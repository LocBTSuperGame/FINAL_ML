{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8b5015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "\n",
    "# Load Data and Base Features\n",
    "DATA_PATH = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e17fcdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All necessary data and feature sets loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "train_log_df = pd.read_csv(os.path.join(DATA_PATH, 'train_log.csv'))\n",
    "\n",
    "base_stats_df = pd.read_csv(r\"C:\\Project\\MALLORN Astronomical Classification Challenge\\train_features.csv\")\n",
    "tsfresh_features_df = pd.read_csv(r\"C:\\Project\\MALLORN Astronomical Classification Challenge\\notebooks\\final_features.csv\")\n",
    "\n",
    "all_lc_df_list = [\n",
    "    pd.read_csv(os.path.join(DATA_PATH, s, 'train_full_lightcurves.csv'))\n",
    "    for s in train_log_df['split'].unique()\n",
    "]\n",
    "\n",
    "full_lc_df = pd.concat(all_lc_df_list).dropna()\n",
    "print(\"All necessary data and feature sets loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8998119f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Engineering HIGH-QUALITY Color features (No Interpolation) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Robust Color Features: 100%|██████████| 3043/3043 [00:07<00:00, 404.67it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Engineering HIGH-QUALITY Color features (No Interpolation) ---\")\n",
    "color_features = []\n",
    "\n",
    "for obj_id, group in tqdm(full_lc_df.groupby('object_id'), desc=\"Calculating Robust Color Features\"):\n",
    "    group = group.sort_values('Time (MJD)')\n",
    "\n",
    "    df_g = group[group['Filter'] == 'g']\n",
    "    df_r = group[group['Filter'] == 'r']\n",
    "    df_i = group[group['Filter'] == 'i']\n",
    "    df_z = group[group['Filter'] == 'z']\n",
    "\n",
    "    # Match within ±1 MJD (≈1 day)\n",
    "    merged_gr = pd.merge_asof(\n",
    "        df_g, df_r, on='Time (MJD)', direction='nearest',\n",
    "        suffixes=('_g', '_r'), tolerance=1.0\n",
    "    )\n",
    "    merged_ri = pd.merge_asof(\n",
    "        df_r, df_i, on='Time (MJD)', direction='nearest',\n",
    "        suffixes=('_r', '_i'), tolerance=1.0\n",
    "    )\n",
    "\n",
    "    merged_gr['g_minus_r'] = merged_gr['Flux_g'] - merged_gr['Flux_r']\n",
    "    merged_ri['r_minus_i'] = merged_ri['Flux_r'] - merged_ri['Flux_i']\n",
    "\n",
    "    obj_stats = {'object_id': obj_id}\n",
    "    for color, df in [('g_minus_r', merged_gr), ('r_minus_i', merged_ri)]:\n",
    "        if not df[color].empty:\n",
    "            obj_stats[f'{color}_mean'] = df[color].mean()\n",
    "            obj_stats[f'{color}_std'] = df[color].std()\n",
    "            obj_stats[f'{color}_skew'] = df[color].skew()\n",
    "        else:\n",
    "            obj_stats[f'{color}_mean'] = np.nan\n",
    "            obj_stats[f'{color}_std'] = np.nan\n",
    "            obj_stats[f'{color}_skew'] = np.nan\n",
    "\n",
    "    color_features.append(obj_stats)\n",
    "\n",
    "color_features_df = pd.DataFrame(color_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d46023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Creating Master Feature Set ---\n",
      "Final Master Feature Set Shape: (3043, 244)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Creating Master Feature Set ---\")\n",
    "\n",
    "master_df = tsfresh_features_df.copy()\n",
    "\n",
    "base_stats_cols = [c for c in base_stats_df.columns if c not in master_df.columns or c == 'object_id']\n",
    "master_df = master_df.merge(base_stats_df[base_stats_cols], on='object_id', how='left')\n",
    "\n",
    "# Add the new high-quality color features\n",
    "master_df = master_df.merge(color_features_df, on='object_id', how='left')\n",
    "\n",
    "# Final cleanup\n",
    "master_df = master_df.fillna(0) # Fill any remaining NaNs with 0\n",
    "print(f\"Final Master Feature Set Shape: {master_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c212d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Training with Master Feature Set ---\n",
      "Scaled 240 numeric features. Kept 2 non-numeric columns unchanged.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(\"\\n--- Final Training with Master Feature Set ---\")\n",
    "y = master_df['target']\n",
    "X = master_df.drop(columns=['object_id', 'target'])\n",
    "\n",
    "# Clean feature names\n",
    "X.columns = [\"\".join(c if c.isalnum() else \"_\" for c in str(x)) for x in X.columns]\n",
    "\n",
    "# Keep only numeric features for scaling\n",
    "numeric_cols = X.select_dtypes(include=['number']).columns\n",
    "X_numeric = X[numeric_cols]\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_numeric)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=numeric_cols, index=X.index)\n",
    "\n",
    "# Combine back with any categorical/non-numeric columns (if you still want them)\n",
    "non_numeric_df = X.drop(columns=numeric_cols)\n",
    "X = pd.concat([X_scaled_df, non_numeric_df], axis=1)\n",
    "\n",
    "print(f\"Scaled {len(numeric_cols)} numeric features. Kept {len(non_numeric_df.columns)} non-numeric columns unchanged.\")\n",
    "\n",
    "# Use the best hyperparameters from your Optuna run\n",
    "best_params = {\n",
    "    'learning_rate': 0.03610120340507472, 'num_leaves': 120, 'max_depth': 11,\n",
    "    'min_child_samples': 80, 'subsample': 0.5577339749020074,\n",
    "    'colsample_bytree': 0.5736019643417907, 'reg_alpha': 0.31579743846984376,\n",
    "    'reg_lambda': 0.3170517208465995, 'objective': 'binary', 'metric': 'binary_logloss',\n",
    "    'boosting_type': 'gbdt', 'n_estimators': 2000, 'device': 'gpu', 'verbose': -1\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11438acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1/5 ---\n",
      "Best F1 Score for fold: 0.3951\n",
      "--- Fold 2/5 ---\n",
      "Best F1 Score for fold: 0.5818\n",
      "--- Fold 3/5 ---\n",
      "Best F1 Score for fold: 0.5909\n",
      "--- Fold 4/5 ---\n",
      "Best F1 Score for fold: 0.4731\n",
      "--- Fold 5/5 ---\n",
      "Best F1 Score for fold: 0.5614\n",
      "\n",
      "--- Final Summary (Master Feature Set) ---\n",
      "Mean F1 Score: 0.5205\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "\n",
    "# Encode object/categorical columns\n",
    "X_fixed = X.copy()\n",
    "for col in X_fixed.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    X_fixed[col] = le.fit_transform(X_fixed[col].astype(str))\n",
    "    \n",
    "# Cross-validation setup\n",
    "N_SPLITS = 5\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "f1_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_fixed, y)):\n",
    "    print(f\"--- Fold {fold+1}/{N_SPLITS} ---\")\n",
    "    X_train, y_train = X_fixed.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_val, y_val = X_fixed.iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "    # Handle class imbalance\n",
    "    pos_count = y_train.value_counts().get(1, 0)\n",
    "    neg_count = y_train.value_counts().get(0, 0)\n",
    "    best_params['scale_pos_weight'] = neg_count / pos_count if pos_count > 0 else 1\n",
    "\n",
    "    # Train LightGBM\n",
    "    model = lgb.LGBMClassifier(**best_params)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_metric='f1',\n",
    "        callbacks=[lgb.early_stopping(100, verbose=False)]\n",
    "    )\n",
    "\n",
    "    # Threshold tuning\n",
    "    val_preds_proba = model.predict_proba(X_val)[:, 1]\n",
    "    thresholds = np.linspace(0.01, 0.99, 100)\n",
    "    f1_values = [f1_score(y_val, (val_preds_proba > t).astype(int)) for t in thresholds]\n",
    "    best_f1 = np.max(f1_values)\n",
    "    f1_scores.append(best_f1)\n",
    "    print(f\"Best F1 Score for fold: {best_f1:.4f}\")\n",
    "\n",
    "print(\"\\n--- Final Summary (Master Feature Set) ---\")\n",
    "print(f\"Mean F1 Score: {np.mean(f1_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62163f1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
