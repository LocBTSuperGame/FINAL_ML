{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f727840e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "063d7ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading and pre-processing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Lightcurves: 100%|██████████| 3043/3043 [00:03<00:00, 883.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing complete.\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = '../data/'\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Load and preprcess data\n",
    "print(\"Loading and pre-processing data...\")\n",
    "train_log_df = pd.read_csv(os.path.join(DATA_PATH, 'train_log.csv'))\n",
    "metadata_full = train_log_df[['object_id', 'Z', 'EBV', 'target']].copy()\n",
    "all_lc_df_list = [pd.read_csv(os.path.join(DATA_PATH, s, 'train_full_lightcurves.csv')) for s in train_log_df['split'].unique()]\n",
    "full_lc_df = pd.concat(all_lc_df_list).dropna()\n",
    "\n",
    "def preprocess_lightcurves(df):\n",
    "    processed_dfs = []\n",
    "    for object_id, group in tqdm(df.groupby('object_id'), desc=\"Processing Lightcurves\"):\n",
    "        group = group.copy()\n",
    "        scaler = StandardScaler()\n",
    "        group[['Flux', 'Flux_err']] = scaler.fit_transform(group[['Flux', 'Flux_err']])\n",
    "        group['Time (MJD)'] = group['Time (MJD)'] - group['Time (MJD)'].min()\n",
    "        processed_dfs.append(group)\n",
    "    return pd.concat(processed_dfs)\n",
    "\n",
    "processed_lc_df = preprocess_lightcurves(full_lc_df)\n",
    "scaler_static = StandardScaler()\n",
    "metadata_full[['Z', 'EBV']] = scaler_static.fit_transform(metadata_full[['Z', 'EBV']])\n",
    "grouped_lc = processed_lc_df.groupby('object_id')\n",
    "print(\"Pre-processing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "547c13b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi Channel PyTorch Dataset and DataLoader\n",
    "FILTERS = ['u', 'g', 'r', 'i', 'z', 'y']\n",
    "\n",
    "class MALLORNMultiChannelDataset(Dataset):\n",
    "    def __init__(self, metadata, grouped_lc):\n",
    "        self.metadata = metadata\n",
    "        self.grouped_lc = grouped_lc\n",
    "        self.object_ids = metadata['object_id'].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.object_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        object_id = self.object_ids[idx]\n",
    "        \n",
    "        # Get data for the object\n",
    "        lc_data = self.grouped_lc.get_group(object_id)\n",
    "        meta_row = self.metadata[self.metadata['object_id'] == object_id]\n",
    "\n",
    "        # Create a dictionary to hold the sequence for each filter\n",
    "        sequences = {}\n",
    "        for f in FILTERS:\n",
    "            filter_data = lc_data[lc_data['Filter'] == f]\n",
    "            # Features are now just Time, Flux, Flux_err\n",
    "            if not filter_data.empty:\n",
    "                sequences[f] = torch.tensor(\n",
    "                    filter_data[['Time (MJD)', 'Flux', 'Flux_err']].values,\n",
    "                    dtype=torch.float32\n",
    "                )\n",
    "            else:\n",
    "                # If no data for this filter, create an empty tensor with correct feature dim\n",
    "                sequences[f] = torch.empty((0, 3), dtype=torch.float32)\n",
    "\n",
    "        static_features = torch.tensor(meta_row[['Z', 'EBV']].values.flatten(), dtype=torch.float32)\n",
    "        target = torch.tensor(float(meta_row['target'].values[0]), dtype=torch.float32)\n",
    "\n",
    "        return {'sequences': sequences, 'static': static_features, 'target': target}\n",
    "\n",
    "def collate_fn_multi_channel(batch):\n",
    "    # This function is more complex as it handles 6 parallel sequences\n",
    "    \n",
    "    # Batch data for each filter separately\n",
    "    batch_sequences = {f: [] for f in FILTERS}\n",
    "    for item in batch:\n",
    "        for f in FILTERS:\n",
    "            batch_sequences[f].append(item['sequences'][f])\n",
    "            \n",
    "    # Pad each filter's sequence list\n",
    "    padded_sequences = {}\n",
    "    for f in FILTERS:\n",
    "        padded_sequences[f] = torch.nn.utils.rnn.pad_sequence(\n",
    "            batch_sequences[f], batch_first=True, padding_value=0.0\n",
    "        )\n",
    "        \n",
    "    statics = torch.stack([item['static'] for item in batch])\n",
    "    targets = torch.stack([item['target'] for item in batch]).unsqueeze(1)\n",
    "    \n",
    "    return {'sequences': padded_sequences, 'static': statics, 'target': targets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aacd6282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running sanity check on the new multi-channel data pipeline...\n",
      "\n",
      "Successfully loaded one multi-channel batch!\n",
      "Shapes of sequence tensors per filter:\n",
      "  Filter 'u': torch.Size([16, 15, 3])\n",
      "  Filter 'g': torch.Size([16, 19, 3])\n",
      "  Filter 'r': torch.Size([16, 46, 3])\n",
      "  Filter 'i': torch.Size([16, 44, 3])\n",
      "  Filter 'z': torch.Size([16, 49, 3])\n",
      "  Filter 'y': torch.Size([16, 36, 3])\n",
      "Shape of static features tensor: torch.Size([16, 2])\n",
      "Shape of target tensor: torch.Size([16, 1])\n",
      "\n",
      "The data pipeline is now ready for the multi-channel model.\n"
     ]
    }
   ],
   "source": [
    "# --- Sanity Check ---\n",
    "print(\"\\nRunning sanity check on the new multi-channel data pipeline...\")\n",
    "train_meta, val_meta = train_test_split(\n",
    "    metadata_full, test_size=0.2, random_state=42, stratify=metadata_full['target']\n",
    ")\n",
    "train_dataset = MALLORNMultiChannelDataset(train_meta, grouped_lc)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn_multi_channel)\n",
    "\n",
    "one_batch = next(iter(train_loader))\n",
    "seq_tensors = one_batch['sequences']\n",
    "static_tensor = one_batch['static']\n",
    "target_tensor = one_batch['target']\n",
    "\n",
    "print(f\"\\nSuccessfully loaded one multi-channel batch!\")\n",
    "print(\"Shapes of sequence tensors per filter:\")\n",
    "for f, tensor in seq_tensors.items():\n",
    "    print(f\"  Filter '{f}': {tensor.shape}\")\n",
    "print(f\"Shape of static features tensor: {static_tensor.shape}\")\n",
    "print(f\"Shape of target tensor: {target_tensor.shape}\")\n",
    "print(\"\\nThe data pipeline is now ready for the multi-channel model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd2ca103",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta, val_meta = train_test_split(metadata_full, test_size=0.2, random_state=42, stratify=metadata_full['target'])\n",
    "train_dataset = MALLORNMultiChannelDataset(train_meta, grouped_lc)\n",
    "val_dataset = MALLORNMultiChannelDataset(val_meta, grouped_lc)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn_multi_channel)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn_multi_channel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1173c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Channel Model Architecture\n",
    "class FilterEncoder(nn.Module):\n",
    "    \"\"\"An expert GRU for a single filter channel.\"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout):\n",
    "        super(FilterEncoder, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True,\n",
    "                          bidirectional=True, dropout=dropout if num_layers > 1 else 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        _, hidden = self.gru(x)\n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
    "        return hidden\n",
    "\n",
    "class MultiChannelClassifier(nn.Module):\n",
    "    def __init__(self, input_size, static_size, hidden_size, num_layers, dropout):\n",
    "        super(MultiChannelClassifier, self).__init__()\n",
    "        \n",
    "        # Create a dictionary of expert encoders, one for each filter\n",
    "        self.filter_encoders = nn.ModuleDict({\n",
    "            f: FilterEncoder(input_size, hidden_size, num_layers, dropout) for f in FILTERS\n",
    "        })\n",
    "        \n",
    "        # The size of the combined feature vector from all GRUs\n",
    "        combined_gru_size = len(FILTERS) * hidden_size * 2 # (bidirectional)\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(combined_gru_size + static_size, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, sequences, static):\n",
    "        filter_outputs = [\n",
    "            self.filter_encoders[f](sequences[f]) for f in FILTERS\n",
    "        ]\n",
    "        \n",
    "        # Concatenate the outputs from all filter encoders\n",
    "        combined_gru_output = torch.cat(filter_outputs, dim=1)\n",
    "        \n",
    "        # Concatenate with static features\n",
    "        final_features = torch.cat((combined_gru_output, static), dim=1)\n",
    "        \n",
    "        # Make final classification\n",
    "        output = self.classifier(final_features)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc12174b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, epochs, learning_rate, pos_weight):\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    best_f1 = -1\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Training]\"):\n",
    "            sequences, statics, targets = batch['sequences'], batch['static'].to(DEVICE), batch['target'].to(DEVICE)\n",
    "            # Move sequence tensors to device\n",
    "            sequences = {f: seq.to(DEVICE) for f, seq in sequences.items()}\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(sequences, statics)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        \n",
    "        # Evaluation with threshold optimization\n",
    "        model.eval()\n",
    "        all_preds_proba, all_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                sequences, statics, targets = batch['sequences'], batch['static'].to(DEVICE), batch['target'].to(DEVICE)\n",
    "                sequences = {f: seq.to(DEVICE) for f, seq in sequences.items()}\n",
    "                outputs = model(sequences, statics)\n",
    "                all_preds_proba.append(torch.sigmoid(outputs).cpu().numpy())\n",
    "                all_targets.append(targets.cpu().numpy())\n",
    "\n",
    "        all_preds_proba = np.concatenate(all_preds_proba).flatten()\n",
    "        all_targets = np.concatenate(all_targets).flatten()\n",
    "        \n",
    "        thresholds = np.linspace(0.01, 0.99, 100)\n",
    "        f1_values = [f1_score(all_targets, (all_preds_proba > t).astype(int)) for t in thresholds]\n",
    "        best_f1_epoch = np.max(f1_values)\n",
    "        best_threshold_epoch = thresholds[np.argmax(f1_values)]\n",
    "        \n",
    "        print(f\"Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | Val F1: {best_f1_epoch:.4f} at Threshold: {best_threshold_epoch:.2f}\")\n",
    "        \n",
    "        if best_f1_epoch > best_f1:\n",
    "            best_f1 = best_f1_epoch\n",
    "            print(f\"New best F1 score: {best_f1:.4f}. Saving model...\")\n",
    "            torch.save(model.state_dict(), 'best_multi_channel_model.pth')\n",
    "            \n",
    "    return best_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0ad3008",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 [Training]: 100%|██████████| 77/77 [00:07<00:00, 10.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 1.4293 | Val F1: 0.1066 at Threshold: 0.78\n",
      "New best F1 score: 0.1066. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 [Training]: 100%|██████████| 77/77 [00:08<00:00,  8.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 1.4411 | Val F1: 0.1075 at Threshold: 0.80\n",
      "New best F1 score: 0.1075. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 [Training]: 100%|██████████| 77/77 [00:08<00:00,  8.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 1.4793 | Val F1: 0.1429 at Threshold: 0.76\n",
      "New best F1 score: 0.1429. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 [Training]: 100%|██████████| 77/77 [00:08<00:00,  8.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Train Loss: 1.4084 | Val F1: 0.1379 at Threshold: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 [Training]: 100%|██████████| 77/77 [00:08<00:00,  9.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Loss: 1.3346 | Val F1: 0.1947 at Threshold: 0.65\n",
      "New best F1 score: 0.1947. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 [Training]: 100%|██████████| 77/77 [00:08<00:00,  8.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Train Loss: 1.3403 | Val F1: 0.1290 at Threshold: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 [Training]: 100%|██████████| 77/77 [00:08<00:00,  8.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Train Loss: 1.2921 | Val F1: 0.1513 at Threshold: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 [Training]: 100%|██████████| 77/77 [00:08<00:00,  8.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Train Loss: 1.3153 | Val F1: 0.1263 at Threshold: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 [Training]: 100%|██████████| 77/77 [00:08<00:00,  8.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Train Loss: 1.2550 | Val F1: 0.1359 at Threshold: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 [Training]: 100%|██████████| 77/77 [00:08<00:00,  8.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 1.3187 | Val F1: 0.1446 at Threshold: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 [Training]: 100%|██████████| 77/77 [00:08<00:00,  8.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 1.2973 | Val F1: 0.1505 at Threshold: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 [Training]: 100%|██████████| 77/77 [00:08<00:00,  8.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 1.2588 | Val F1: 0.1333 at Threshold: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 [Training]: 100%|██████████| 77/77 [00:08<00:00,  8.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 1.2542 | Val F1: 0.1168 at Threshold: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 [Training]: 100%|██████████| 77/77 [00:08<00:00,  8.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 1.3752 | Val F1: 0.1231 at Threshold: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 [Training]: 100%|██████████| 77/77 [00:08<00:00,  8.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 1.2886 | Val F1: 0.1333 at Threshold: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 [Training]: 100%|██████████| 77/77 [00:08<00:00,  8.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 1.3138 | Val F1: 0.1102 at Threshold: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 [Training]: 100%|██████████| 77/77 [00:08<00:00,  8.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 1.3924 | Val F1: 0.1266 at Threshold: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 [Training]: 100%|██████████| 77/77 [00:08<00:00,  8.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 1.2898 | Val F1: 0.1057 at Threshold: 0.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 [Training]: 100%|██████████| 77/77 [00:09<00:00,  8.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 1.2743 | Val F1: 0.1046 at Threshold: 0.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 [Training]: 100%|██████████| 77/77 [00:09<00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 1.3554 | Val F1: 0.1090 at Threshold: 0.34\n",
      "\n",
      "--- Training Finished ---\n",
      "Best validation F1 score achieved with Multi-Channel model: 0.1947\n"
     ]
    }
   ],
   "source": [
    "# Run Pipeline\n",
    "# Hyperparameters\n",
    "INPUT_SIZE = 3      \n",
    "STATIC_SIZE = 2     \n",
    "HIDDEN_SIZE = 64    \n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.5\n",
    "EPOCHS = 20         \n",
    "LEARNING_RATE = 5e-4 \n",
    "\n",
    "pos_count = train_meta['target'].sum()\n",
    "neg_count = len(train_meta) - pos_count\n",
    "pos_weight = torch.tensor([neg_count / pos_count], device=DEVICE)\n",
    "\n",
    "model = MultiChannelClassifier(INPUT_SIZE, STATIC_SIZE, HIDDEN_SIZE, NUM_LAYERS, DROPOUT).to(DEVICE)\n",
    "final_f1 = train_model(model, train_loader, val_loader, EPOCHS, LEARNING_RATE, pos_weight)\n",
    "\n",
    "print(f\"\\n--- Training Finished ---\")\n",
    "print(f\"Best validation F1 score achieved with Multi-Channel model: {final_f1:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
